{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e45445c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3c6b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating optimized trash collection points table\n"
     ]
    }
   ],
   "source": [
    "# Set credentials\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/dariaserbichenko/code/DariaSerb/key-gcp/trash-optimizer-479913-91e59ecc96c9.json\"\n",
    "\n",
    "PROJECT = \"trash-optimizer-479913\"\n",
    "DATASET = \"nantes\"\n",
    "client = bigquery.Client(project=PROJECT)\n",
    "\n",
    "print(\"Creating optimized trash collection points table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b97fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Querying alimentary_garbage_clean (food waste)\n"
     ]
    }
   ],
   "source": [
    "# FIRST QUERY ALIMENTARY_GARBAGE (FOOD WASTE)\n",
    "\n",
    "print(\"\\n1. Querying alimentary_garbage_clean (food waste)\")\n",
    "\n",
    "query1 = f\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER () as ID,\n",
    "  CONCAT('Food Waste - ', COALESCE(commune, 'Nantes')) as Name,\n",
    "  COALESCE(adresse, 'Address not specified') as Address,\n",
    "  lon as Longitude,\n",
    "  lat as Latitude,\n",
    "  0 as Is_Cardboard_enabled,\n",
    "  1 as Is_Food_enabled,\n",
    "  0 as Is_Glass_enabled,\n",
    "  0 as Is_Metal_enabled,\n",
    "  0 as Is_Paper_enabled,\n",
    "  0 as Is_Plastic_enabled,\n",
    "  0 as Is_Textile_enabled,\n",
    "  0 as Is_Vegetation_enabled,\n",
    "  0 as Is_Neon_enabled,\n",
    "  0 as Is_Cartridge_enabled,\n",
    "  0 as Is_Lamp_Light_enabled\n",
    "FROM `{PROJECT}.{DATASET}.alimentary_garbage_clean`\n",
    "WHERE lat IS NOT NULL AND lon IS NOT NULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d72dcd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1,644 food waste locations\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df1 = client.query(query1).to_dataframe()\n",
    "    print(f\"Retrieved {len(df1):,} food waste locations\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    df1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5a98cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Querying ecopoints with actual columns\n"
     ]
    }
   ],
   "source": [
    "# SECOND QUERY ECOPOINTS (USING ACTUAL COLUMNS FOUND)\n",
    "\n",
    "print(\"\\n2. Querying ecopoints with actual columns\")\n",
    "\n",
    "# From inspection: columns are ['bois', 'carton', 'cartouche', 'neon', 'papier', 'textile', 'verre']\n",
    "\n",
    "query2 = f\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER () + 10000 as ID,\n",
    "  CONCAT('Recycling Center - ', COALESCE(nom, commune, 'Ecopoint')) as Name,\n",
    "  COALESCE(adresse, 'Address not specified') as Address,\n",
    "  lon as Longitude,\n",
    "  lat as Latitude,\n",
    "\n",
    "  -- Use actual columns found\n",
    "  CASE WHEN UPPER(carton) = 'OUI' THEN 1 ELSE 0 END as Is_Cardboard_enabled,\n",
    "  0 as Is_Food_enabled,\n",
    "  CASE WHEN UPPER(verre) = 'OUI' THEN 1 ELSE 0 END as Is_Glass_enabled,\n",
    "  0 as Is_Metal_enabled,  -- No metal column found\n",
    "  CASE WHEN UPPER(papier) = 'OUI' THEN 1 ELSE 0 END as Is_Paper_enabled,\n",
    "  0 as Is_Plastic_enabled,  -- No plastique column\n",
    "  CASE WHEN UPPER(textile) = 'OUI' THEN 1 ELSE 0 END as Is_Textile_enabled,\n",
    "  0 as Is_Vegetation_enabled,  -- No vegetal column\n",
    "  CASE WHEN UPPER(neon) = 'OUI' THEN 1 ELSE 0 END as Is_Neon_enabled,\n",
    "  CASE WHEN UPPER(cartouche) = 'OUI' THEN 1 ELSE 0 END as Is_Cartridge_enabled,\n",
    "  0 as Is_Lamp_Light_enabled  -- No ampoule column\n",
    "FROM `{PROJECT}.{DATASET}.ecopoints`\n",
    "WHERE lat IS NOT NULL AND lon IS NOT NULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d33dfd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 15 recycling centers with actual waste types\n",
      "- Waste acceptance in recycling centers:\n",
      "   Cardboard: 15/15 locations\n",
      "   Glass: 14/15 locations\n",
      "   Paper: 15/15 locations\n",
      "   Textile: 9/15 locations\n",
      "   Neon: 8/15 locations\n",
      "   Cartridge: 15/15 locations\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df2 = client.query(query2).to_dataframe()\n",
    "    print(f\"Retrieved {len(df2)} recycling centers with actual waste types\")\n",
    "\n",
    "    # Check acceptance rates\n",
    "    waste_cols = [col for col in df2.columns if col.startswith('Is_')]\n",
    "    print(f\"- Waste acceptance in recycling centers:\")\n",
    "    for col in waste_cols:\n",
    "        count = df2[col].sum()\n",
    "        if count > 0:\n",
    "            waste_name = col.replace('Is_', '').replace('_enabled', '').replace('_', ' ').title()\n",
    "            print(f\"   {waste_name}: {count}/{len(df2)} locations\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Error: {e}\")\n",
    "    df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f06a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Querying collection_centres_pdl\n"
     ]
    }
   ],
   "source": [
    "# 3. QUERY COLLECTION_CENTRES_PDL (SIMPLIFIED)\n",
    "\n",
    "print(\"\\n3. Querying collection_centres_pdl\")\n",
    "\n",
    "# Simple query without problematic columns\n",
    "\n",
    "query3 = f\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER () + 20000 as ID, -- Prevents conflicts with IDs from other tables\n",
    "  CONCAT('Waste Center - ', COALESCE(N_SERVICE, 'PDL Center')) as Name,\n",
    "  'Contact facility for address' as Address,\n",
    "  lon as Longitude,\n",
    "  lat as Latitude,\n",
    "  1 as Is_Cardboard_enabled,\n",
    "  1 as Is_Food_enabled,\n",
    "  1 as Is_Glass_enabled,\n",
    "  1 as Is_Metal_enabled,\n",
    "  1 as Is_Paper_enabled,\n",
    "  1 as Is_Plastic_enabled,\n",
    "  1 as Is_Textile_enabled,\n",
    "  1 as Is_Vegetation_enabled,\n",
    "  1 as Is_Neon_enabled,\n",
    "  1 as Is_Cartridge_enabled,\n",
    "  1 as Is_Lamp_Light_enabled\n",
    "FROM `{PROJECT}.{DATASET}.collection_centres_pdl`\n",
    "WHERE lat IS NOT NULL AND lon IS NOT NULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1e0498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 328 waste centers\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df3 = client.query(query3).to_dataframe()\n",
    "    print(f\"Retrieved {len(df3):,} waste centers\")\n",
    "except Exception as e:\n",
    "    print(f\"   ❌ Error: {e}\")\n",
    "    df3 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27e64d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING FINAL TRASH COLLECTION POINTS TABLE\n",
      "Food waste points: 1,644\n",
      "Recycling centers: 15\n",
      "Waste centers: 328\n",
      "FINAL TABLE: 1,987 total trash collection points\n",
      "CSV saved: 'trash_collection_points_final_optimized.csv'\n",
      "Uploading to BigQuery\n",
      "BigQuery table created: trash-optimizer-479913.nantes.trash_collection_points\n",
      "   Rows: 1,987\n",
      "   Size: 0.31 MB\n"
     ]
    }
   ],
   "source": [
    "# COMBINE AND CREATE FINAL TABLE\n",
    "\n",
    "print(\"CREATING FINAL TRASH COLLECTION POINTS TABLE\")\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "if not df1.empty:\n",
    "    all_dataframes.append(df1)\n",
    "    print(f\"Food waste points: {len(df1):,}\")\n",
    "if not df2.empty:\n",
    "    all_dataframes.append(df2)\n",
    "    print(f\"Recycling centers: {len(df2)}\")\n",
    "if not df3.empty:\n",
    "    all_dataframes.append(df3)\n",
    "    print(f\"Waste centers: {len(df3):,}\")\n",
    "\n",
    "if all_dataframes:\n",
    "    # Combine all data\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "    # Reset ID to be sequential\n",
    "    combined_df['ID'] = range(1, len(combined_df) + 1)\n",
    "\n",
    "    # Define final structure\n",
    "    final_columns = [\n",
    "        'ID', 'Name', 'Address', 'Longitude', 'Latitude',\n",
    "        'Is_Cardboard_enabled', 'Is_Food_enabled', 'Is_Glass_enabled',\n",
    "        'Is_Metal_enabled', 'Is_Paper_enabled', 'Is_Plastic_enabled',\n",
    "        'Is_Textile_enabled', 'Is_Vegetation_enabled', 'Is_Neon_enabled',\n",
    "        'Is_Cartridge_enabled', 'Is_Lamp_Light_enabled'\n",
    "    ]\n",
    "\n",
    "    # Ensure all columns exist\n",
    "    for col in final_columns:\n",
    "        if col not in combined_df.columns:\n",
    "            if col.startswith('Is_'):\n",
    "                combined_df[col] = 0\n",
    "\n",
    "    # Convert to proper types\n",
    "    for col in combined_df.columns:\n",
    "        if col.startswith('Is_'):\n",
    "            combined_df[col] = combined_df[col].astype(int)\n",
    "        elif col in ['Longitude', 'Latitude']:\n",
    "            combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
    "\n",
    "    # Reorder\n",
    "    combined_df = combined_df[final_columns]\n",
    "\n",
    "    total_locations = len(combined_df)\n",
    "    print(f\"FINAL TABLE: {total_locations:,} total trash collection points\")\n",
    "\n",
    "    # Save to CSV\n",
    "    output_csv = 'trash_collection_points_final_optimized.csv'\n",
    "    combined_df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"CSV saved: '{output_csv}'\")\n",
    "\n",
    "    # ===== UPLOAD TO BIGQUERY =====\n",
    "    print(f\"Uploading to BigQuery\")\n",
    "    table_id = f\"{PROJECT}.{DATASET}.trash_collection_points\"\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\",\n",
    "        autodetect=True,\n",
    "        max_bad_records=100\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        job = client.load_table_from_dataframe(combined_df, table_id, job_config=job_config)\n",
    "        job.result()\n",
    "\n",
    "        table = client.get_table(table_id)\n",
    "        print(f\"BigQuery table created: {table_id}\")\n",
    "        print(f\"   Rows: {table.num_rows:,}\")\n",
    "        print(f\"   Size: {table.num_bytes / (1024*1024):.2f} MB\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BigQuery upload failed: {e}\")\n",
    "        print(f\"   Data saved locally: '{output_csv}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65bc994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAILED ANALYSIS\n",
      "\n",
      "1. FACILITY TYPES:\n",
      "   Food Waste            1,644 locations ( 82.7%)\n",
      "\n",
      "2. WASTE TYPE ACCEPTANCE:\n",
      "   Food                  1,972 locations ( 99.2%)\n",
      "   Cardboard               343 locations ( 17.3%)\n",
      "   Paper                   343 locations ( 17.3%)\n",
      "   Cartridge               343 locations ( 17.3%)\n",
      "   Glass                   342 locations ( 17.2%)\n",
      "   Textile                 337 locations ( 17.0%)\n",
      "   Neon                    336 locations ( 16.9%)\n",
      "   Metal                   328 locations ( 16.5%)\n",
      "   Plastic                 328 locations ( 16.5%)\n",
      "   Vegetation              328 locations ( 16.5%)\n",
      "   Lamp Light              328 locations ( 16.5%)\n",
      "\n",
      "3. GEOGRAPHIC COVERAGE:\n",
      "   Latitude range:  46.3452 to 48.4623\n",
      "   Longitude range: -2.5062 to 0.7777\n",
      "   Center point:    (47.2611, -1.4583)\n",
      "\n",
      "4. CREATING SUMMARY REPORTS\n",
      "Excel report saved: 'trash_collection_analysis.xlsx'\n",
      "\n",
      "5. QUICK STATS:\n",
      "   Total locations in database: 1,987\n",
      "   Locations with coordinates: 1,987\n",
      "   Top 3 accepted waste types:\n",
      "     1. Food (1,972 locations, 99.2%)\n",
      "     2. Cardboard (343 locations, 17.3%)\n",
      "     3. Paper (343 locations, 17.3%)\n",
      "PROCESS COMPLETE\n",
      "   Total trash collection points: 1,987\n",
      "   BigQuery table: trash-optimizer-479913.nantes.trash_collection_points\n",
      "   Local files created:\n",
      "     - trash_collection_points_final_optimized.csv (main data)\n",
      "     - trash_collection_analysis.xlsx (analysis report)\n",
      "   Waste Center            328 locations ( 16.5%)\n",
      "\n",
      "2. WASTE TYPE ACCEPTANCE:\n",
      "   Food                  1,972 locations ( 99.2%)\n",
      "   Cardboard               343 locations ( 17.3%)\n",
      "   Paper                   343 locations ( 17.3%)\n",
      "   Cartridge               343 locations ( 17.3%)\n",
      "   Glass                   342 locations ( 17.2%)\n",
      "   Textile                 337 locations ( 17.0%)\n",
      "   Neon                    336 locations ( 16.9%)\n",
      "   Metal                   328 locations ( 16.5%)\n",
      "   Plastic                 328 locations ( 16.5%)\n",
      "   Vegetation              328 locations ( 16.5%)\n",
      "   Lamp Light              328 locations ( 16.5%)\n",
      "\n",
      "3. GEOGRAPHIC COVERAGE:\n",
      "   Latitude range:  46.3452 to 48.4623\n",
      "   Longitude range: -2.5062 to 0.7777\n",
      "   Center point:    (47.2611, -1.4583)\n",
      "\n",
      "4. CREATING SUMMARY REPORTS\n",
      "Excel report saved: 'trash_collection_analysis.xlsx'\n",
      "\n",
      "5. QUICK STATS:\n",
      "   Total locations in database: 1,987\n",
      "   Locations with coordinates: 1,987\n",
      "   Top 3 accepted waste types:\n",
      "     1. Food (1,972 locations, 99.2%)\n",
      "     2. Cardboard (343 locations, 17.3%)\n",
      "     3. Paper (343 locations, 17.3%)\n",
      "PROCESS COMPLETE\n",
      "   Total trash collection points: 1,987\n",
      "   BigQuery table: trash-optimizer-479913.nantes.trash_collection_points\n",
      "   Local files created:\n",
      "     - trash_collection_points_final_optimized.csv (main data)\n",
      "     - trash_collection_analysis.xlsx (analysis report)\n",
      "   Recycling Center         15 locations (  0.8%)\n",
      "\n",
      "2. WASTE TYPE ACCEPTANCE:\n",
      "   Food                  1,972 locations ( 99.2%)\n",
      "   Cardboard               343 locations ( 17.3%)\n",
      "   Paper                   343 locations ( 17.3%)\n",
      "   Cartridge               343 locations ( 17.3%)\n",
      "   Glass                   342 locations ( 17.2%)\n",
      "   Textile                 337 locations ( 17.0%)\n",
      "   Neon                    336 locations ( 16.9%)\n",
      "   Metal                   328 locations ( 16.5%)\n",
      "   Plastic                 328 locations ( 16.5%)\n",
      "   Vegetation              328 locations ( 16.5%)\n",
      "   Lamp Light              328 locations ( 16.5%)\n",
      "\n",
      "3. GEOGRAPHIC COVERAGE:\n",
      "   Latitude range:  46.3452 to 48.4623\n",
      "   Longitude range: -2.5062 to 0.7777\n",
      "   Center point:    (47.2611, -1.4583)\n",
      "\n",
      "4. CREATING SUMMARY REPORTS\n",
      "Excel report saved: 'trash_collection_analysis.xlsx'\n",
      "\n",
      "5. QUICK STATS:\n",
      "   Total locations in database: 1,987\n",
      "   Locations with coordinates: 1,987\n",
      "   Top 3 accepted waste types:\n",
      "     1. Food (1,972 locations, 99.2%)\n",
      "     2. Cardboard (343 locations, 17.3%)\n",
      "     3. Paper (343 locations, 17.3%)\n",
      "PROCESS COMPLETE\n",
      "   Total trash collection points: 1,987\n",
      "   BigQuery table: trash-optimizer-479913.nantes.trash_collection_points\n",
      "   Local files created:\n",
      "     - trash_collection_points_final_optimized.csv (main data)\n",
      "     - trash_collection_analysis.xlsx (analysis report)\n",
      "No data was retrieved\n"
     ]
    }
   ],
   "source": [
    "# CREATE DETAILED ANALYSIS\n",
    "\n",
    "print(f\"DETAILED ANALYSIS\")\n",
    "\n",
    "\n",
    "# 1. Facility type breakdown\n",
    "\n",
    "print(f\"\\n1. FACILITY TYPES:\")\n",
    "facility_summary = combined_df['Name'].str.extract(r'^(Food Waste|Recycling Center|Waste Center)')[0]\n",
    "type_counts = facility_summary.value_counts()\n",
    "\n",
    "for type_name, count in type_counts.items():\n",
    "    percentage = (count / total_locations) * 100\n",
    "    print(f\"   {type_name:20} {count:6,} locations ({percentage:5.1f}%)\")\n",
    "\n",
    "# 2. Waste type acceptance\n",
    "\n",
    "    print(f\"\\n2. WASTE TYPE ACCEPTANCE:\")\n",
    "    waste_cols = [col for col in combined_df.columns if col.startswith('Is_')]\n",
    "\n",
    "    waste_stats = []\n",
    "    for col in waste_cols:\n",
    "        count = combined_df[col].sum()\n",
    "        percentage = (count / total_locations) * 100\n",
    "        waste_name = col.replace('Is_', '').replace('_enabled', '').replace('_', ' ').title()\n",
    "        waste_stats.append((waste_name, count, percentage))\n",
    "\n",
    "# Sort by most accepted\n",
    "    waste_stats.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for name, count, pct in waste_stats:\n",
    "        print(f\"   {name:20} {count:6,} locations ({pct:5.1f}%)\")\n",
    "\n",
    "# 3. Geographic coverage\n",
    "\n",
    "    print(f\"\\n3. GEOGRAPHIC COVERAGE:\")\n",
    "    if combined_df['Latitude'].notna().any() and combined_df['Longitude'].notna().any():\n",
    "        min_lat = combined_df['Latitude'].min()\n",
    "        max_lat = combined_df['Latitude'].max()\n",
    "        min_lon = combined_df['Longitude'].min()\n",
    "        max_lon = combined_df['Longitude'].max()\n",
    "\n",
    "        print(f\"   Latitude range:  {min_lat:.4f} to {max_lat:.4f}\")\n",
    "        print(f\"   Longitude range: {min_lon:.4f} to {max_lon:.4f}\")\n",
    "        print(f\"   Center point:    ({combined_df['Latitude'].mean():.4f}, {combined_df['Longitude'].mean():.4f})\")\n",
    "\n",
    "# 4. Create summary DataFrame\n",
    "\n",
    "    print(f\"\\n4. CREATING SUMMARY REPORTS\")\n",
    "\n",
    "# Summary by waste type\n",
    "\n",
    "    summary_data = []\n",
    "    for name, count, pct in waste_stats:\n",
    "        summary_data.append({\n",
    "            'Waste Type': name,\n",
    "            'Locations Accepting': count,\n",
    "            'Percentage': f\"{pct:.1f}%\",\n",
    "            'Acceptance Rate': pct/100\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # Summary by facility type\n",
    "    facility_df = pd.DataFrame({\n",
    "        'Facility Type': type_counts.index,\n",
    "        'Count': type_counts.values,\n",
    "        'Percentage': [f\"{(val/total_locations)*100:.1f}%\" for val in type_counts.values]\n",
    "    })\n",
    "\n",
    "# Save reports\n",
    "\n",
    "    try:\n",
    "\n",
    "# Excel report with multiple sheets\n",
    "\n",
    "        excel_file = 'trash_collection_analysis.xlsx'\n",
    "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "            combined_df.to_excel(writer, sheet_name='All Locations', index=False)\n",
    "            summary_df.to_excel(writer, sheet_name='Waste Type Summary', index=False)\n",
    "            facility_df.to_excel(writer, sheet_name='Facility Type Summary', index=False)\n",
    "\n",
    "# Add location density analysis\n",
    "\n",
    "            if combined_df['Latitude'].notna().any():\n",
    "\n",
    "# Simple density by rounding coordinates\n",
    "\n",
    "                density_df = combined_df.copy()\n",
    "                density_df['Lat_rounded'] = density_df['Latitude'].round(2)\n",
    "                density_df['Lon_rounded'] = density_df['Longitude'].round(2)\n",
    "                density_summary = density_df.groupby(['Lat_rounded', 'Lon_rounded']).size().reset_index(name='Count')\n",
    "                density_summary.to_excel(writer, sheet_name='Location Density', index=False)\n",
    "\n",
    "        print(f\"Excel report saved: '{excel_file}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Excel report failed: {e}\")\n",
    "\n",
    "# Still save CSV summaries\n",
    "\n",
    "        summary_df.to_csv('waste_type_summary.csv', index=False)\n",
    "        facility_df.to_csv('facility_type_summary.csv', index=False)\n",
    "        print(f\"CSV summaries saved\")\n",
    "\n",
    "# 5. Quick stats\n",
    "\n",
    "    print(f\"\\n5. QUICK STATS:\")\n",
    "    print(f\"   Total locations in database: {total_locations:,}\")\n",
    "    print(f\"   Locations with coordinates: {combined_df['Latitude'].notna().sum():,}\")\n",
    "\n",
    "# Most common waste types\n",
    "\n",
    "    top_3 = waste_stats[:3]\n",
    "    print(f\"   Top 3 accepted waste types:\")\n",
    "    for i, (name, count, pct) in enumerate(top_3, 1):\n",
    "        print(f\"     {i}. {name} ({count:,} locations, {pct:.1f}%)\")\n",
    "\n",
    "    print(f\"PROCESS COMPLETE\")\n",
    "    print(f\"   Total trash collection points: {total_locations:,}\")\n",
    "    print(f\"   BigQuery table: {table_id}\")\n",
    "    print(f\"   Local files created:\")\n",
    "    print(f\"     - {output_csv} (main data)\")\n",
    "    if os.path.exists('trash_collection_analysis.xlsx'):\n",
    "        print(f\"     - trash_collection_analysis.xlsx (analysis report)\")\n",
    "\n",
    "else:\n",
    "    print(\"No data was retrieved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trash-optimizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
