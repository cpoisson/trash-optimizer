{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e45445c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3c6b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating optimized trash collection points table\n"
     ]
    }
   ],
   "source": [
    "# Set credentials\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/dariaserbichenko/code/DariaSerb/key-gcp/trash-optimizer-479913-91e59ecc96c9.json\"\n",
    "\n",
    "PROJECT = \"trash-optimizer-479913\"\n",
    "DATASET = \"nantes\"\n",
    "client = bigquery.Client(project=PROJECT)\n",
    "\n",
    "print(\"Creating optimized trash collection points table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b97fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Querying alimentary_garbage_clean (food waste)\n"
     ]
    }
   ],
   "source": [
    "# FIRST QUERY ALIMENTARY_GARBAGE (FOOD WASTE)\n",
    "\n",
    "print(\"\\n1. Querying alimentary_garbage_clean (food waste)\")\n",
    "\n",
    "query1 = f\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER () as ID,\n",
    "  CONCAT('Food Waste - ', COALESCE(commune, 'Nantes')) as Name,\n",
    "  COALESCE(adresse, 'Address not specified') as Address,\n",
    "  lon as Longitude,\n",
    "  lat as Latitude,\n",
    "  0 as Is_Cardboard_enabled,\n",
    "  1 as Is_Food_enabled,\n",
    "  0 as Is_Glass_enabled,\n",
    "  0 as Is_Metal_enabled,\n",
    "  0 as Is_Paper_enabled,\n",
    "  0 as Is_Plastic_enabled,\n",
    "  0 as Is_Textile_enabled,\n",
    "  0 as Is_Vegetation_enabled,\n",
    "  0 as Is_Neon_enabled,\n",
    "  0 as Is_Cartridge_enabled,\n",
    "  0 as Is_Lamp_Light_enabled\n",
    "FROM `{PROJECT}.{DATASET}.alimentary_garbage_clean`\n",
    "WHERE lat IS NOT NULL AND lon IS NOT NULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d72dcd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1,644 food waste locations\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df1 = client.query(query1).to_dataframe()\n",
    "    print(f\"Retrieved {len(df1):,} food waste locations\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    df1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a98cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Querying ecopoints with actual columns\n"
     ]
    }
   ],
   "source": [
    "# SECOND QUERY ECOPOINTS (USING ACTUAL COLUMNS FOUND)\n",
    "\n",
    "print(\"\\n2. Querying ecopoints with actual columns\")\n",
    "\n",
    "# From inspection: columns are ['bois', 'carton', 'ferraille', 'cartouche', 'neon', 'papier', 'textile', 'verre']\n",
    "\n",
    "query2 = f\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER () + 10000 as ID,\n",
    "  CONCAT('Recycling Center - ', COALESCE(nom, commune, 'Ecopoint')) as Name,\n",
    "  COALESCE(adresse, 'Address not specified') as Address,\n",
    "  lon as Longitude,\n",
    "  lat as Latitude,\n",
    "\n",
    "  -- Use actual columns found\n",
    "  CASE WHEN UPPER(carton) = 'OUI' THEN 1 ELSE 0 END as Is_Cardboard_enabled,\n",
    "  0 as Is_Food_enabled,\n",
    "  CASE WHEN UPPER(verre) = 'OUI' THEN 1 ELSE 0 END as Is_Glass_enabled,\n",
    "  CASE WHEN UPPER(ferraille) = 'OUI' THEN 1 ELSE 0 END as Is_Metal_enabled,\n",
    "  CASE WHEN UPPER(papier) = 'OUI' THEN 1 ELSE 0 END as Is_Paper_enabled,\n",
    "  CASE WHEN UPPER(dechet_vert) = 'OUI' THEN 1 ELSE 0 END as Is_Vegetation_enabled,\n",
    "  0 as Is_Plastic_enabled,  -- No plastique column\n",
    "  CASE WHEN UPPER(textile) = 'OUI' THEN 1 ELSE 0 END as Is_Textile_enabled,\n",
    "  CASE WHEN UPPER(neon) = 'OUI' THEN 1 ELSE 0 END as Is_Neon_enabled,\n",
    "  CASE WHEN UPPER(cartouche) = 'OUI' THEN 1 ELSE 0 END as Is_Cartridge_enabled,\n",
    "  0 as Is_Lamp_Light_enabled  -- No ampoule column\n",
    "FROM `{PROJECT}.{DATASET}.ecopoints`\n",
    "WHERE lat IS NOT NULL AND lon IS NOT NULL\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d33dfd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 15 recycling centers with actual waste types\n",
      "- Waste acceptance in recycling centers:\n",
      "   Cardboard: 15/15 locations\n",
      "   Glass: 14/15 locations\n",
      "   Metal: 14/15 locations\n",
      "   Paper: 15/15 locations\n",
      "   Vegetation: 14/15 locations\n",
      "   Textile: 9/15 locations\n",
      "   Neon: 8/15 locations\n",
      "   Cartridge: 15/15 locations\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df2 = client.query(query2).to_dataframe()\n",
    "    print(f\"Retrieved {len(df2)} recycling centers with actual waste types\")\n",
    "\n",
    "    # Check acceptance rates\n",
    "    waste_cols = [col for col in df2.columns if col.startswith('Is_')]\n",
    "    print(f\"- Waste acceptance in recycling centers:\")\n",
    "    for col in waste_cols:\n",
    "        count = df2[col].sum()\n",
    "        if count > 0:\n",
    "            waste_name = col.replace('Is_', '').replace('_enabled', '').replace('_', ' ').title()\n",
    "            print(f\"   {waste_name}: {count}/{len(df2)} locations\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error: {e}\")\n",
    "    df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dcfddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Querying glass collection columns (Verre only)\n",
      "‚úÖ Retrieved 1,079 glass collection columns\n",
      "\n",
      "üìä GLASS COLUMNS SUMMARY:\n",
      "  Total glass columns: 1,079\n",
      "  With valid coordinates: 1,079\n",
      "\n",
      "üëÄ SAMPLE GLASS COLUMNS (first 3):\n",
      "  1. Drop-off points - Underground - Nantes\n",
      "     Address: Rue de la petite Sensive...\n",
      "     Location: (47.260437, -1.561580)\n",
      "     Glass enabled: ‚úì\n",
      "  2. Drop-off points - Underground - Nantes\n",
      "     Address: Rue Blaise Pascal...\n",
      "     Location: (47.256204, -1.566761)\n",
      "     Glass enabled: ‚úì\n",
      "  3. Drop-off points - Underground - Nantes\n",
      "     Address: 2 Rue de Concarneau...\n",
      "     Location: (47.264360, -1.578521)\n",
      "     Glass enabled: ‚úì\n",
      "\n",
      "üóëÔ∏è  WASTE TYPE ENABLEMENT (should be Glass only):\n",
      "  Glass: 1,079/1,079 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# THIRD QUERY FOR GLASS COLLECTION COLUMNS (VERRE ONLY)\n",
    "\n",
    "print(\"\\n3. Querying glass collection columns (Verre only)\")\n",
    "\n",
    "query3 = f\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER () + 30000 as ID,  # Start from 30000 for glass columns\n",
    "  CONCAT(\n",
    "    'Drop-off points - ',\n",
    "    COALESCE(\n",
    "      CASE\n",
    "        WHEN type_colonne IS NOT NULL THEN\n",
    "          CASE type_colonne\n",
    "            WHEN 'colonne enterr√©e' THEN 'Underground'\n",
    "            WHEN 'colonne a√©rienne' THEN 'Above-ground'\n",
    "            ELSE INITCAP(type_colonne)\n",
    "          END\n",
    "        ELSE ''\n",
    "      END,\n",
    "      'Glass Collection'\n",
    "    ),\n",
    "    CASE\n",
    "      WHEN commune IS NOT NULL THEN CONCAT(' - ', commune)\n",
    "      ELSE ' - Nantes'\n",
    "    END\n",
    "  ) as Name,\n",
    "  COALESCE(adresse, 'Nantes M√©tropole') as Address,\n",
    "  lat as Latitude,\n",
    "  lon as Longitude,\n",
    "\n",
    "  -- Waste type capabilities: ONLY GLASS ENABLED\n",
    "  0 as Is_Cardboard_enabled,\n",
    "  0 as Is_Food_enabled,\n",
    "  1 as Is_Glass_enabled,  # All these points are for glass collection\n",
    "  0 as Is_Metal_enabled,\n",
    "  0 as Is_Paper_enabled,\n",
    "  0 as Is_Plastic_enabled,\n",
    "  0 as Is_Textile_enabled,\n",
    "  0 as Is_Vegetation_enabled,\n",
    "  0 as Is_Neon_enabled,\n",
    "  0 as Is_Cartridge_enabled,\n",
    "  0 as Is_Lamp_Light_enabled\n",
    "\n",
    "FROM `{PROJECT}.{DATASET}.location_dropoff_points_nantes`\n",
    "WHERE\n",
    "  lat IS NOT NULL\n",
    "  AND lon IS NOT NULL\n",
    "  AND LOWER(TRIM(type_dechet)) = 'verre'  # Only glass collection points\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df3 = client.query(query3).to_dataframe()\n",
    "    print(f\"‚úÖ Retrieved {len(df3):,} glass collection columns\")\n",
    "\n",
    "    # Show summary\n",
    "    print(f\"\\nüìä GLASS COLUMNS SUMMARY:\")\n",
    "    print(f\"  Total glass columns: {len(df3):,}\")\n",
    "\n",
    "    # Check coordinate validity\n",
    "    valid_coords = df3['Latitude'].notna().sum()\n",
    "    print(f\"  With valid coordinates: {valid_coords:,}\")\n",
    "\n",
    "    # Show sample\n",
    "    print(f\"\\nüëÄ SAMPLE GLASS COLUMNS (first 3):\")\n",
    "    for i in range(min(3, len(df3))):\n",
    "        row = df3.iloc[i]\n",
    "        print(f\"  {i+1}. {row['Name']}\")\n",
    "        print(f\"     Address: {row['Address'][:60]}...\")\n",
    "        print(f\"     Location: ({row['Latitude']:.6f}, {row['Longitude']:.6f})\")\n",
    "        print(f\"     Glass enabled: {'‚úì' if row['Is_Glass_enabled'] == 1 else '‚úó'}\")\n",
    "\n",
    "    # Show waste type summary\n",
    "    print(f\"\\nüóëÔ∏è  WASTE TYPE ENABLEMENT (should be Glass only):\")\n",
    "    waste_cols = [col for col in df3.columns if col.startswith('Is_')]\n",
    "    for col in waste_cols:\n",
    "        count = df3[col].sum()\n",
    "        if count > 0:\n",
    "            waste_name = col.replace('Is_', '').replace('_enabled', '').replace('_', ' ').title()\n",
    "            print(f\"  {waste_name}: {count:,}/{len(df3):,} ({count/len(df3)*100:.1f}%)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error querying glass columns: {e}\")\n",
    "\n",
    "    # Debug: Check what types of waste exist in the table\n",
    "    print(\"\\nüîç Debug: Checking available waste types in the table...\")\n",
    "    try:\n",
    "        debug_query = f\"\"\"\n",
    "        SELECT\n",
    "          type_dechet,\n",
    "          COUNT(*) as count\n",
    "        FROM `{PROJECT}.{DATASET}.location_dropoff_points_nantes`\n",
    "        WHERE type_dechet IS NOT NULL\n",
    "        GROUP BY type_dechet\n",
    "        ORDER BY count DESC\n",
    "        LIMIT 10\n",
    "        \"\"\"\n",
    "        waste_types = client.query(debug_query).to_dataframe()\n",
    "        print(f\"Available waste types in table:\")\n",
    "        print(waste_types.to_string(index=False))\n",
    "    except:\n",
    "        print(\"Could not check waste types\")\n",
    "\n",
    "    df3 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1aa7d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Querying non-glass waste columns with waste type names\n",
      "‚úÖ Retrieved 1,490 non-glass waste columns\n",
      "\n",
      "üìä BREAKDOWN BY WASTE TYPE:\n",
      "  Household Waste: 843 columns (56.6%)\n",
      "  Recyclable Waste: 564 columns (37.9%)\n",
      "  Paper/Cardboard: 83 columns (5.6%)\n",
      "\n",
      "üóëÔ∏è  CAPABILITIES BY WASTE TYPE:\n",
      "\n",
      "  Paper/Cardboard columns accept:\n",
      "    ‚úì Cardboard, Paper\n",
      "\n",
      "  Recyclable Waste columns accept:\n",
      "    ‚úì Cardboard, Glass, Metal, Paper, Plastic\n",
      "\n",
      "  Household Waste columns accept:\n",
      "    ‚úì Cardboard, Food, Glass, Metal, Paper, Plastic, Vegetation\n",
      "\n",
      "üëÄ SAMPLES (one of each type):\n",
      "\n",
      "  Paper/Cardboard:\n",
      "    Name: Paper/Cardboard Drop-off Point - Nantes (Above-ground)\n",
      "    Original Type: Papier-carton\n",
      "    Location: Nantes\n",
      "    Coordinates: (47.229835, -1.519756)\n",
      "\n",
      "  Recyclable Waste:\n",
      "    Name: Recyclable Waste Drop-off Point - Basse-Goulaine (Underground)\n",
      "    Original Type: D√©chet recyclable\n",
      "    Location: Basse-Goulaine\n",
      "    Coordinates: (47.208462, -1.466821)\n",
      "\n",
      "  Household Waste:\n",
      "    Name: Household Waste Drop-off Point - Basse-Goulaine (Underground)\n",
      "    Original Type: Ordure m√©nag√®re\n",
      "    Location: Basse-Goulaine\n",
      "    Coordinates: (47.214656, -1.467335)\n",
      "    Accepts: Cardboard, Food, Glass, Metal, Paper, Plastic, Textile, Vegetation, Neon, Cartridge, Lamp Light\n",
      "\n",
      "üìç DISTRIBUTION BY COMMUNE (top 5):\n",
      "  Nantes: 872 columns\n",
      "  Saint-Herblain: 226 columns\n",
      "  Rez√©: 122 columns\n",
      "  Carquefou: 55 columns\n",
      "  Vertou: 48 columns\n"
     ]
    }
   ],
   "source": [
    "# FOURTH QUERY: NON-GLASS WASTE TYPES\n",
    "\n",
    "print(\"\\n4. Querying non-glass waste columns with waste type names\")\n",
    "\n",
    "query4 = f\"\"\"\n",
    "SELECT\n",
    "  ROW_NUMBER() OVER () +\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%papier%carton%' THEN 40000\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%' THEN 50000\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 60000\n",
    "    ELSE 70000\n",
    "  END as ID,\n",
    "\n",
    "  CONCAT(\n",
    "    CASE\n",
    "      WHEN LOWER(TRIM(type_dechet)) LIKE '%papier%carton%' THEN 'Paper/Cardboard'\n",
    "      WHEN LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%' THEN 'Recyclable Waste'\n",
    "      WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 'Household Waste'\n",
    "      ELSE INITCAP(type_dechet)\n",
    "    END,\n",
    "    ' Drop-off Point - ',\n",
    "    COALESCE(commune, 'Nantes'),\n",
    "    CASE\n",
    "      WHEN type_colonne IS NOT NULL THEN CONCAT(' (',\n",
    "        CASE type_colonne\n",
    "          WHEN 'colonne enterr√©e' THEN 'Underground'\n",
    "          WHEN 'colonne a√©rienne' THEN 'Above-ground'\n",
    "          ELSE INITCAP(type_colonne)\n",
    "        END, ')')\n",
    "      ELSE ''\n",
    "    END\n",
    "  ) as Name,\n",
    "\n",
    "  COALESCE(adresse, 'Nantes M√©tropole') as Address,\n",
    "  lat as Latitude,\n",
    "  lon as Longitude,\n",
    "\n",
    "  -- Paper/Cardboard columns\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%papier%carton%' THEN 1\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%' THEN 1\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 1\n",
    "    ELSE 0\n",
    "  END as Is_Cardboard_enabled,\n",
    "\n",
    "  -- Food (only for household waste)\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 1\n",
    "    ELSE 0\n",
    "  END as Is_Food_enabled,\n",
    "\n",
    "  -- Glass (for recyclable and household waste - but NOT paper/cardboard)\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%' THEN 1\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 1\n",
    "    ELSE 0\n",
    "  END as Is_Glass_enabled,\n",
    "\n",
    "  -- Metal (for recyclable and household waste)\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%' THEN 1\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 1\n",
    "    ELSE 0\n",
    "  END as Is_Metal_enabled,\n",
    "\n",
    "  -- Paper (for paper/cardboard, recyclable, and household)\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%papier%carton%' THEN 1\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%' THEN 1\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 1\n",
    "    ELSE 0\n",
    "  END as Is_Paper_enabled,\n",
    "\n",
    "  -- Plastic (for recyclable and household)\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%' THEN 1\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 1\n",
    "    ELSE 0\n",
    "  END as Is_Plastic_enabled,\n",
    "\n",
    "  -- Textile (only for household)\n",
    "  0 as Is_Textile_enabled,\n",
    "\n",
    "  -- Vegetation (only for household)\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 1\n",
    "    ELSE 0\n",
    "  END as Is_Vegetation_enabled,\n",
    "\n",
    "  -- Special waste types (none for these columns)\n",
    "  0 as Is_Neon_enabled,\n",
    "  0 as Is_Cartridge_enabled,\n",
    "  0 as Is_Lamp_Light_enabled,\n",
    "\n",
    "  type_dechet as Original_Waste_Type,\n",
    "  type_colonne as Original_Column_Type,\n",
    "  commune as Commune\n",
    "\n",
    "FROM `{PROJECT}.{DATASET}.location_dropoff_points_nantes`\n",
    "WHERE\n",
    "  lat IS NOT NULL\n",
    "  AND lon IS NOT NULL\n",
    "  AND (\n",
    "    LOWER(TRIM(type_dechet)) LIKE '%papier%carton%'\n",
    "    OR LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%'\n",
    "    OR LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%'\n",
    "  )\n",
    "ORDER BY\n",
    "  CASE\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%papier%carton%' THEN 1\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%d√©chet recyclable%' THEN 2\n",
    "    WHEN LOWER(TRIM(type_dechet)) LIKE '%ordure m√©nag√®re%' THEN 3\n",
    "    ELSE 4\n",
    "  END,\n",
    "  commune\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df4 = client.query(query4).to_dataframe()\n",
    "    print(f\"‚úÖ Retrieved {len(df4):,} non-glass waste columns\")\n",
    "\n",
    "    # Show breakdown\n",
    "    print(f\"\\nüìä BREAKDOWN BY WASTE TYPE:\")\n",
    "    if 'Original_Waste_Type' in df4.columns:\n",
    "        # Group by cleaned waste type name\n",
    "        df4['Waste_Category'] = df4['Original_Waste_Type'].apply(\n",
    "            lambda x: 'Paper/Cardboard' if 'papier' in str(x).lower() and 'carton' in str(x).lower()\n",
    "            else 'Recyclable Waste' if 'd√©chet recyclable' in str(x).lower()\n",
    "            else 'Household Waste' if 'ordure m√©nag√®re' in str(x).lower()\n",
    "            else 'Other'\n",
    "        )\n",
    "\n",
    "        waste_counts = df4['Waste_Category'].value_counts()\n",
    "        for waste_type, count in waste_counts.items():\n",
    "            percentage = (count / len(df4)) * 100\n",
    "            print(f\"  {waste_type}: {count:,} columns ({percentage:.1f}%)\")\n",
    "\n",
    "    # Show what each type accepts\n",
    "    print(f\"\\nüóëÔ∏è  CAPABILITIES BY WASTE TYPE:\")\n",
    "    waste_categories = df4['Waste_Category'].unique() if 'Waste_Category' in df4.columns else df4['Original_Waste_Type'].unique()\n",
    "\n",
    "    for category in waste_categories:\n",
    "        if 'Waste_Category' in df4.columns:\n",
    "            subset = df4[df4['Waste_Category'] == category]\n",
    "        else:\n",
    "            subset = df4[df4['Original_Waste_Type'] == category]\n",
    "\n",
    "        if len(subset) > 0:\n",
    "            print(f\"\\n  {category} columns accept:\")\n",
    "            enabled_types = []\n",
    "            for col in [c for c in subset.columns if c.startswith('Is_') and c not in ['Is_Neon_enabled', 'Is_Cartridge_enabled', 'Is_Lamp_Light_enabled']]:\n",
    "                if subset[col].iloc[0] == 1:\n",
    "                    waste_name = col.replace('Is_', '').replace('_enabled', '').replace('_', ' ').title()\n",
    "                    enabled_types.append(waste_name)\n",
    "\n",
    "            if enabled_types:\n",
    "                print(f\"    ‚úì {', '.join(enabled_types)}\")\n",
    "            else:\n",
    "                print(f\"    ‚úó No specific waste types enabled\")\n",
    "\n",
    "    # Show samples\n",
    "    print(f\"\\nüëÄ SAMPLES (one of each type):\")\n",
    "    sample_shown = set()\n",
    "\n",
    "    for _, row in df4.iterrows():\n",
    "        waste_type = row['Original_Waste_Type']\n",
    "        if waste_type not in sample_shown:\n",
    "            sample_shown.add(waste_type)\n",
    "\n",
    "            category = row.get('Waste_Category', waste_type)\n",
    "            print(f\"\\n  {category}:\")\n",
    "            print(f\"    Name: {row['Name']}\")\n",
    "            print(f\"    Original Type: {row['Original_Waste_Type']}\")\n",
    "            print(f\"    Location: {row['Commune']}\")\n",
    "            print(f\"    Coordinates: ({row['Latitude']:.6f}, {row['Longitude']:.6f})\")\n",
    "\n",
    "            # Show enabled types\n",
    "            enabled = []\n",
    "            for col in [c for c in row.index if c.startswith('Is_') and row[col] == 1]:\n",
    "                waste_name = col.replace('Is_', '').replace('_enabled', '').replace('_', ' ').title()\n",
    "                enabled.append(waste_name)\n",
    "            if enabled:\n",
    "                print(f\"    Accepts: {', '.join(enabled)}\")\n",
    "\n",
    "            # Limit to 3 samples\n",
    "            if len(sample_shown) >= 3:\n",
    "                break\n",
    "\n",
    "    # Show distribution by commune\n",
    "    print(f\"\\nüìç DISTRIBUTION BY COMMUNE (top 5):\")\n",
    "    if 'Commune' in df4.columns:\n",
    "        commune_counts = df4['Commune'].value_counts().head(5)\n",
    "        for commune, count in commune_counts.items():\n",
    "            print(f\"  {commune}: {count:,} columns\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    # Try exact match if LIKE doesn't work\n",
    "    print(\"\\nüîÑ Trying with exact matches...\")\n",
    "    try:\n",
    "        query4_exact = f\"\"\"\n",
    "        SELECT\n",
    "          ROW_NUMBER() OVER () +\n",
    "          CASE\n",
    "            WHEN type_dechet = 'Papier-carton' THEN 40000\n",
    "            WHEN type_dechet = 'D√©chet recyclable' THEN 50000\n",
    "            WHEN type_dechet = 'Ordure m√©nag√®re' THEN 60000\n",
    "            ELSE 70000\n",
    "          END as ID,\n",
    "\n",
    "          CONCAT(\n",
    "            CASE\n",
    "              WHEN type_dechet = 'Papier-carton' THEN 'Paper/Cardboard'\n",
    "              WHEN type_dechet = 'D√©chet recyclable' THEN 'Recyclable Waste'\n",
    "              WHEN type_dechet = 'Ordure m√©nag√®re' THEN 'Household Waste'\n",
    "              ELSE type_dechet\n",
    "            END,\n",
    "            ' Column - ',\n",
    "            COALESCE(commune, 'Nantes')\n",
    "          ) as Name,\n",
    "\n",
    "          COALESCE(adresse, 'Nantes M√©tropole') as Address,\n",
    "          lat as Latitude,\n",
    "          lon as Longitude,\n",
    "\n",
    "          -- Capabilities (simplified for testing)\n",
    "          1 as Is_Cardboard_enabled,\n",
    "          0 as Is_Food_enabled,\n",
    "          0 as Is_Glass_enabled,\n",
    "          0 as Is_Metal_enabled,\n",
    "          1 as Is_Paper_enabled,\n",
    "          0 as Is_Plastic_enabled,\n",
    "          0 as Is_Textile_enabled,\n",
    "          0 as Is_Vegetation_enabled,\n",
    "          0 as Is_Neon_enabled,\n",
    "          0 as Is_Cartridge_enabled,\n",
    "          0 as Is_Lamp_Light_enabled,\n",
    "\n",
    "          type_dechet as Original_Waste_Type,\n",
    "          commune as Commune\n",
    "\n",
    "        FROM `{PROJECT}.{DATASET}.location_dropoff_points_nantes`\n",
    "        WHERE lat IS NOT NULL AND lon IS NOT NULL\n",
    "          AND type_dechet IN ('Papier-carton', 'D√©chet recyclable', 'Ordure m√©nag√®re')\n",
    "        LIMIT 100\n",
    "        \"\"\"\n",
    "\n",
    "        df4 = client.query(query4_exact).to_dataframe()\n",
    "        print(f\"‚úÖ Retrieved {len(df4):,} columns with exact matching\")\n",
    "\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Exact match also failed: {e2}\")\n",
    "        df4 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27e64d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING FINAL TRASH COLLECTION POINTS TABLE\n",
      "Food waste points: 1,644\n",
      "Recycling centers: 15\n",
      "Underground containers: 1,079\n",
      "Underground containers (other type waste): 1,490\n",
      "FINAL TABLE: 4,228 total trash collection points\n",
      "CSV saved: 'trash_collection_points_final_optimized.csv'\n",
      "Uploading to BigQuery\n",
      "BigQuery table created: trash-optimizer-479913.nantes.trash_collection_points\n",
      "   Rows: 4,228\n",
      "   Size: 0.71 MB\n"
     ]
    }
   ],
   "source": [
    "# COMBINE AND CREATE FINAL TABLE\n",
    "\n",
    "print(\"CREATING FINAL TRASH COLLECTION POINTS TABLE\")\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "if not df1.empty:\n",
    "    all_dataframes.append(df1)\n",
    "    print(f\"Food waste points: {len(df1):,}\")\n",
    "if not df2.empty:\n",
    "    all_dataframes.append(df2)\n",
    "    print(f\"Recycling centers: {len(df2)}\")\n",
    "if not df3.empty:\n",
    "    all_dataframes.append(df3)\n",
    "    print(f\"Underground containers: {len(df3):,}\")\n",
    "if not df4.empty:\n",
    "    all_dataframes.append(df4)\n",
    "    print(f\"Underground containers (other type waste): {len(df4):,}\")\n",
    "\n",
    "if all_dataframes:\n",
    "    # Combine all data\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "    # Reset ID to be sequential\n",
    "    combined_df['ID'] = range(1, len(combined_df) + 1)\n",
    "\n",
    "    # Define final structure\n",
    "    final_columns = [\n",
    "        'ID', 'Name', 'Address', 'Longitude', 'Latitude',\n",
    "        'Is_Cardboard_enabled', 'Is_Food_enabled', 'Is_Glass_enabled',\n",
    "        'Is_Metal_enabled', 'Is_Paper_enabled', 'Is_Plastic_enabled',\n",
    "        'Is_Textile_enabled', 'Is_Vegetation_enabled', 'Is_Neon_enabled',\n",
    "        'Is_Cartridge_enabled', 'Is_Lamp_Light_enabled'\n",
    "    ]\n",
    "\n",
    "    # Ensure all columns exist\n",
    "    for col in final_columns:\n",
    "        if col not in combined_df.columns:\n",
    "            if col.startswith('Is_'):\n",
    "                combined_df[col] = 0\n",
    "\n",
    "    # Convert to proper types\n",
    "    for col in combined_df.columns:\n",
    "        if col.startswith('Is_'):\n",
    "            combined_df[col] = combined_df[col].astype(int)\n",
    "        elif col in ['Longitude', 'Latitude']:\n",
    "            combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n",
    "\n",
    "    # Reorder\n",
    "    combined_df = combined_df[final_columns]\n",
    "\n",
    "    total_locations = len(combined_df)\n",
    "    print(f\"FINAL TABLE: {total_locations:,} total trash collection points\")\n",
    "\n",
    "    # Save to CSV\n",
    "    output_csv = 'trash_collection_points_final_optimized.csv'\n",
    "    combined_df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"CSV saved: '{output_csv}'\")\n",
    "\n",
    "    # ===== UPLOAD TO BIGQUERY =====\n",
    "    print(f\"Uploading to BigQuery\")\n",
    "    table_id = f\"{PROJECT}.{DATASET}.trash_collection_points\"\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=\"WRITE_TRUNCATE\",\n",
    "        autodetect=True,\n",
    "        max_bad_records=100\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        job = client.load_table_from_dataframe(combined_df, table_id, job_config=job_config)\n",
    "        job.result()\n",
    "\n",
    "        table = client.get_table(table_id)\n",
    "        print(f\"BigQuery table created: {table_id}\")\n",
    "        print(f\"   Rows: {table.num_rows:,}\")\n",
    "        print(f\"   Size: {table.num_bytes / (1024*1024):.2f} MB\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BigQuery upload failed: {e}\")\n",
    "        print(f\"   Data saved locally: '{output_csv}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65bc994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAILED ANALYSIS FOR TRASH COLLECTION POINTS\n",
      "\n",
      "1. FACILITY TYPES:\n",
      "   Food Waste            1,644 locations ( 38.9%)\n",
      "\n",
      "2. WASTE TYPE ACCEPTANCE:\n",
      "   Glass                 2,500 locations ( 59.1%)\n",
      "   Food                  2,487 locations ( 58.8%)\n",
      "   Cardboard             1,505 locations ( 35.6%)\n",
      "   Paper                 1,505 locations ( 35.6%)\n",
      "   Metal                 1,421 locations ( 33.6%)\n",
      "   Plastic               1,407 locations ( 33.3%)\n",
      "   Vegetation              857 locations ( 20.3%)\n",
      "   Cartridge                15 locations (  0.4%)\n",
      "   Textile                   9 locations (  0.2%)\n",
      "   Neon                      8 locations (  0.2%)\n",
      "   Lamp Light                0 locations (  0.0%)\n",
      "\n",
      "3. GEOGRAPHIC COVERAGE:\n",
      "   Latitude range:  47.1225 to 47.3335\n",
      "   Longitude range: -1.8177 to -1.3820\n",
      "   Center point:    (47.2249, -1.5594)\n",
      "   Recycling Center         15 locations (  0.4%)\n",
      "\n",
      "2. WASTE TYPE ACCEPTANCE:\n",
      "   Glass                 2,500 locations ( 59.1%)\n",
      "   Food                  2,487 locations ( 58.8%)\n",
      "   Cardboard             1,505 locations ( 35.6%)\n",
      "   Paper                 1,505 locations ( 35.6%)\n",
      "   Metal                 1,421 locations ( 33.6%)\n",
      "   Plastic               1,407 locations ( 33.3%)\n",
      "   Vegetation              857 locations ( 20.3%)\n",
      "   Cartridge                15 locations (  0.4%)\n",
      "   Textile                   9 locations (  0.2%)\n",
      "   Neon                      8 locations (  0.2%)\n",
      "   Lamp Light                0 locations (  0.0%)\n",
      "\n",
      "3. GEOGRAPHIC COVERAGE:\n",
      "   Latitude range:  47.1225 to 47.3335\n",
      "   Longitude range: -1.8177 to -1.3820\n",
      "   Center point:    (47.2249, -1.5594)\n"
     ]
    }
   ],
   "source": [
    "# CREATE DETAILED ANALYSIS\n",
    "\n",
    "print(f\"DETAILED ANALYSIS FOR TRASH COLLECTION POINTS\")\n",
    "\n",
    "# 1. Facility type breakdown\n",
    "\n",
    "print(f\"\\n1. FACILITY TYPES:\")\n",
    "facility_summary = combined_df['Name'].str.extract(r'^(Food Waste|Recycling Center|Underground containers)')[0]\n",
    "type_counts = facility_summary.value_counts()\n",
    "\n",
    "for type_name, count in type_counts.items():\n",
    "    percentage = (count / total_locations) * 100\n",
    "    print(f\"   {type_name:20} {count:6,} locations ({percentage:5.1f}%)\")\n",
    "\n",
    "# 2. Waste type acceptance\n",
    "\n",
    "    print(f\"\\n2. WASTE TYPE ACCEPTANCE:\")\n",
    "    waste_cols = [col for col in combined_df.columns if col.startswith('Is_')]\n",
    "\n",
    "    waste_stats = []\n",
    "    for col in waste_cols:\n",
    "        count = combined_df[col].sum()\n",
    "        percentage = (count / total_locations) * 100\n",
    "        waste_name = col.replace('Is_', '').replace('_enabled', '').replace('_', ' ').title()\n",
    "        waste_stats.append((waste_name, count, percentage))\n",
    "\n",
    "# Sort by most accepted\n",
    "\n",
    "    waste_stats.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for name, count, pct in waste_stats:\n",
    "        print(f\"   {name:20} {count:6,} locations ({pct:5.1f}%)\")\n",
    "\n",
    "# 3. Geographic coverage\n",
    "\n",
    "    print(f\"\\n3. GEOGRAPHIC COVERAGE:\")\n",
    "    if combined_df['Latitude'].notna().any() and combined_df['Longitude'].notna().any():\n",
    "        min_lat = combined_df['Latitude'].min()\n",
    "        max_lat = combined_df['Latitude'].max()\n",
    "        min_lon = combined_df['Longitude'].min()\n",
    "        max_lon = combined_df['Longitude'].max()\n",
    "\n",
    "        print(f\"   Latitude range:  {min_lat:.4f} to {max_lat:.4f}\")\n",
    "        print(f\"   Longitude range: {min_lon:.4f} to {max_lon:.4f}\")\n",
    "        print(f\"   Center point:    ({combined_df['Latitude'].mean():.4f}, {combined_df['Longitude'].mean():.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trash-optimizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
